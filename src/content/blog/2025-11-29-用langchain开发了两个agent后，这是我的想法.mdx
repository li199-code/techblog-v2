---
title: "用langchain开发了两个智能体后，这是我的想法"
authors: Jason
date: 2025-11-29
description: "agent开发过程回顾"
tags: ["langchain", "agent"]
---
import LinkCard from "@components/LinkCard.astro";
import Callout from "@components/Callout.astro";

不管你承不承认，2025年都可称得上是一个Agent开发的年份。大模型底座对工具调用能力的支持，让开发者能够利用大模型的强大能力，开发出各种复杂的应用。

## 两种范式：agent和workflow

我开发了两个智能体，一个是agent架构，一个是workflow架构。关于他们的区别如下：

<LinkCard
  title="LangGraph 文档"
  link="https://docs.langchain.com/oss/javascript/langgraph/workflows-agents"
  description="agent和workflow的区别"
/>

agent自主决定何时调用工具，而workflow则是严格按照定义的流程执行。在langchain代码层面，agent是通过`createAgent`函数创建的，而workflow是通过`addNode`等函数手动添加节点和有向边的。

他们的适用场景也不相同。Workflow的核心是预设的、线性的、确定性的执行路径。它非常适合逻辑清晰、步骤固定、不需要或少需要“临场判断”的任务，比如订单流水线处理。Agent的核心是感知、决策、行动的循环。它具备自主性和推理能力，适合处理复杂、开放、需要“动脑筋”的任务。比如客户服务、智能助手等。

第一个智能体是一个deep research智能体，负责分析用户问题，生成详细的研究报告。它的工作流程如下：

1. 接收用户问题作为输入
2. 制定研究计划
3. 利用搜索引擎等工具，收集相关的研究材料
4. 对收集到的材料进行分析和总结
5. 生成详细的研究报告，包括问题描述、研究方法、实验结果、结论等

第二个智能体是一个助手，负责意图识别，并规范化用户提出的问题。它的工作流程如下：

1. 接收用户咨询作为输入
2. 利用知识库和预定义的回答模板，生成规范化的问题

## 提示词

修改提示词的过程中，往往遇到指令遵循不佳，这个和模型能力有关。现阶段，国内的deepseek，qwen、zhipu等厂商，指令遵循能力最强的是deepseek。其他厂商的模型，比如qwen，只适合一问一答的chatbot类场景，如果提示词涉及if-else流程和多步决策，qwen就会表现得很懒。

这里我贴一个我认为有指导意义的提示词指南：

<LinkCard
  title="提示词指南"
  link="https://v2.docs.nocobase.com/cn/ai-employees/configuration/prompt-engineering-guide"
  description="提示词指南"
/>

## 调用工具

deep research的返回很慢，常常需要20分钟。中间根据研究计划搜寻相关素材的步骤最耗时。应该把这种工具调用做到并行化，能使返回速度快很多。

## 复现结果

经常会遇到某次智能体输出的结果和预期不一致。但是再运行相同的输入时，结果又会变成预期的结果。这给调试带来了不方便。为了降低随机性，可以有以下措施：

- 【必选】设置固定种子：始终在LLM调用中传递 seed 参数。
- 【必选】使用最低温度：将 temperature 设置为 0。
- 【强烈推荐】结构化输出：要求Agent以JSON等结构化格式输出，并提供明确的模式。
- 【强烈推荐】工具/函数约束：将Agent的能力范围限制在你预定义好的工具集内，强制其进行函数调用。
- 【推荐】编写精确的提示词：提供清晰、无歧义的指令和步骤，减少模型的猜测空间。
- 【可选】实现验证层：在关键任务中，添加一个额外的步骤来验证Agent输出的合理性和一致性。
- 【环境一致性】: 确保运行环境（模型版本、代码、提示词）保持不变。

## 其他

在开发langchain智能体时，langchain发布了新的1.0版本。官网文档也随之更新。无论是网页版的gpt，还是IDE中的编出助手，都没有相关语料。甚至很多官方文档的代码示例都无法执行。这导致了在开发过程中，很多问题都需要自己去解决。也就是说，即使进入了AI时代，在少数场景中，仍需要我们具备'google - 调试 - 反思'的开发能力。
